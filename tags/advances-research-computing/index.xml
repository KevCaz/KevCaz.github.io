<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Advances Research Computing on KevCaz's Website</title><link>https://kevcaz.github.io/tags/advances-research-computing/</link><description>Recent content in Advances Research Computing on KevCaz's Website</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>Content under CC0 1.0 Universal unless otherwise specified.</copyright><lastBuildDate>Thu, 20 Aug 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://kevcaz.github.io/tags/advances-research-computing/index.xml" rel="self" type="application/rss+xml"/><item><title>Running parallel simulations with scripts that take two or more varying parameters</title><link>https://kevcaz.github.io/notes/computesci/multi_parameters/</link><pubDate>Thu, 20 Aug 2020 00:00:00 +0000</pubDate><guid>https://kevcaz.github.io/notes/computesci/multi_parameters/</guid><description>Another note about how I work with Slurm! Today, I comment on three strategies to run simulations for which the values taken by two arguments (or more) vary from one simulation to another.
The problem Let&amp;rsquo;s assume that we run simulations by calling a Julia script myscript.jl that takes p1 as argument, in order to run the simulation on one CPU for a single simulation, I would run the following bas command</description></item><item><title>Array job with Slurm: a use case and a mistake I made!</title><link>https://kevcaz.github.io/notes/computesci/arrayjob/</link><pubDate>Fri, 19 Jun 2020 00:00:00 +0000</pubDate><guid>https://kevcaz.github.io/notes/computesci/arrayjob/</guid><description>‚ö†Ô∏è I won&amp;rsquo;t introduce Slurm here as I already have written several notes about it (see the Slurm tag).
Today, I needed to send 171 jobs to the server. All jobs were similar similar, only the species ID was changing, exactly the kind of computation array jobs were designed for. As there are 32 cpus per nodes, I figured I needed 6 nodes. And so I wrote the following bash script:</description></item><item><title>Submitting a Julia script with Slurm</title><link>https://kevcaz.github.io/notes/computesci/juliaslurm/</link><pubDate>Fri, 01 May 2020 00:00:00 +0000</pubDate><guid>https://kevcaz.github.io/notes/computesci/juliaslurm/</guid><description>In a previous note, I&amp;rsquo;ve narrated my transition from Mammoth to Graham and I&amp;rsquo;ve exemplified how to submit an job with Slurm. As I&amp;rsquo;m currently using Julia for several projects, I&amp;rsquo;d like to report how I submitted my Julia script to the scheduler.
First of all, I needed to set up Julia for my account. As Graham runs under CentOS and as I had already loaded Julia v1.3.11, I just had to update the version of Julia with module.</description></item><item><title>Combining Slurm and GNU parallel</title><link>https://kevcaz.github.io/notes/computesci/slurmandgnuparallel/</link><pubDate>Mon, 11 Nov 2019 00:00:00 +0000</pubDate><guid>https://kevcaz.github.io/notes/computesci/slurmandgnuparallel/</guid><description>Last week, I attended a &amp;ldquo;Midi conf√©rence&amp;rdquo; (basically a one hour training session during lunch time) offered by Compute Canada dealing with Slurm, GNU Parallel and how to combine them. This was a very useful and timely presentation for me (üá´üá∑ slides available online üîó) as I&amp;rsquo;ve just got started with Slurm (see my previous notes on the topic) and was eager to learn more.
Earlier today, I found an opportunity to put in practice what I&amp;rsquo;ve learned last week.</description></item><item><title>From Mammoth to Graham</title><link>https://kevcaz.github.io/notes/computesci/graham/</link><pubDate>Thu, 19 Sep 2019 00:00:00 +0000</pubDate><guid>https://kevcaz.github.io/notes/computesci/graham/</guid><description>Compute Canada is awesome! Seriously, it is! As explained on its website:
Compute Canada, in partnership with regional organizations ACENET, Calcul Qu√©bec, Compute Ontario and WestGrid, leads the acceleration of research and innovation by deploying state-of-the-art advanced research computing (ARC) systems, storage and software solutions. Together we provide essential ARC services and infrastructure for Canadian researchers and their collaborators in all academic and industrial sectors. Our world-class team of more than 200 experts employed by 37 partner universities and research institutions across the country provide direct support to research teams.</description></item></channel></rss>